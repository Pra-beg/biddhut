{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3345438a-5334-4fa7-a166-378170a6e33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import os\n",
    "import mimetypes\n",
    "from slugify import slugify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4af2e783",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_directory(directory_path):\n",
    "    \"\"\"Creates directory if it does not already exist\"\"\"\n",
    "    if not os.path.exists(directory_path):\n",
    "        os.makedirs(directory_path)\n",
    "        print(f\"Directory '{directory_path}' created.\")\n",
    "    else:\n",
    "        print(f\"Directory '{directory_path}' already exists.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/likheketo/Desktop/prabeg/biddhut/venv/lib/python3.11/site-packages/urllib3/connectionpool.py:1103: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.customs.gov.np'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "url = \"https://www.customs.gov.np/page/fts-fy-208081\"\n",
    "\n",
    "# send request to url to fetch html page\n",
    "res = requests.get(url, verify=False)\n",
    "# raise exception if status not 200 ie OK\n",
    "res.raise_for_status()\n",
    "\n",
    "# use bs4 to parse html page\n",
    "soup = BeautifulSoup(res.text, 'html.parser')\n",
    "# select ul element that contains list of fiscal year links\n",
    "ul_element = soup.select_one('.news')\n",
    "\n",
    "# parse links from ul list\n",
    "links = {}\n",
    "for li in ul_element.find_all('li'):\n",
    "    # title is used to extract fiscal year\n",
    "    title = li.text\n",
    "    # regex to find fiscal year as they are formatted as:  वैदेशिक व्यापारको तथ्यांक आ. ब. २०७७/७८\n",
    "    # ie. 4 digits followed by / and some characters? and then 2 digits\n",
    "    match = re.findall(r'(\\d{4}).*(\\d{2})', title)\n",
    "\n",
    "    if match:\n",
    "        match = match[0]\n",
    "        year = f\"fy-{int(match[0])}-{int(match[1])}\"\n",
    "    else:\n",
    "        raise Exception(\"unable to parse fiscal year\")\n",
    " \n",
    "    # link to page containing fall files for the fiscal year\n",
    "    link = li.find('a').get('href')\n",
    "    links[year] = link\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1df4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to base dir to store all fiscal year data\n",
    "base_dir = \"data\"\n",
    "for fy, link in links.items():\n",
    "    # dir to store all data for that fiscal year\n",
    "    fy_dir = os.path.join(base_dir, fy)\n",
    "    # if fiscal year folder exists, assume data exists so skip download\n",
    "    if os.path.exists(fy_dir):\n",
    "        print(f'directory for {fy} already exists, skipping downloads')\n",
    "        continue\n",
    "    create_directory(fy_dir)\n",
    "    # making request to link of fiscal year document\n",
    "    res = requests.get(link, verify=False)\n",
    "    res.raise_for_status()\n",
    "\n",
    "    # parse the html text\n",
    "    soup = BeautifulSoup(res.text, 'html.parser')\n",
    "\n",
    "    # select ul tag that contains list of file links\n",
    "    ul_element = soup.select_one('.style1 > ul:nth-child(2)')\n",
    "\n",
    "    for li in ul_element.find_all('li'):\n",
    "        # use this text as name of file as it contains year and month of data\n",
    "        title = slugify(li.text)\n",
    "        # link of excel/pdf files\n",
    "        link = li.find('a').get('href')\n",
    "        # make request for file\n",
    "        res = requests.get(link, verify=False)\n",
    "        res.raise_for_status()\n",
    "\n",
    "        # determine mime type of file \n",
    "        mime_type = res.headers.get('Content-Type')\n",
    "        extension = mimetypes.guess_extension(mime_type) or '.unknown'\n",
    "\n",
    "        # save file with filename from title and extension as determined\n",
    "        with open(os.path.join(fy_dir, title+extension), 'wb') as f:\n",
    "            f.write(res.content)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
