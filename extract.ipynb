{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script does lump of work in cleaning and transforming the data. The data before fiscal year 2074/75 is discarded due to non-uniformity. The monthly data has values cumulated to that month from start of fiscal year. So data had to be transformed accordingly, only then it could be merged. So, this script handles tasks including:\n",
    "\n",
    "- Reading excel files for each fiscal year, month wise\n",
    "- Cleaining and structuring the data into a structured format: `hscode | description | unit | quantity | value | revenue`\n",
    "- Subtracting values from previous month to get actual values for the month.\n",
    "- Merging the data of all months in fiscal year.\n",
    "- Tagging fiscal year and month in data.\n",
    "- Merging the data for every fiscal year to produce unified csv of format: `fy | month | hscode | description | unit | quantity | value | revenue`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "from difflib import get_close_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slugified month names are one of these, so a manually mapped dict is used to get month number\n",
    "months = {\n",
    "    'vaishaakh':1,\n",
    "    'jetth':2,\n",
    "    'jessth':2,\n",
    "    'asaadh':3,\n",
    "    'shraavnn':4,\n",
    "    'bhaadr':5,\n",
    "    'aashvin':6,\n",
    "    'asoj':6,\n",
    "    'kaartik':7,\n",
    "    'mangshir':8,\n",
    "    'maarg': 8,\n",
    "    'pauss':9,\n",
    "    'maagh':10,\n",
    "    'phaagun':11,\n",
    "    'caitr':12\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fy-2074-75',\n",
       " 'fy-2075-76',\n",
       " 'fy-2076-77',\n",
       " 'fy-2077-78',\n",
       " 'fy-2078-79',\n",
       " 'fy-2079-80',\n",
       " 'fy-2080-81']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# each dir inside data dir is treated as dir containing data for a fiscal year\n",
    "fy_dirs = os.listdir('data')\n",
    "# omit years preceeding 2074 due to un-uniformity of data\n",
    "fy_dirs = [fy for fy in fy_dirs if int(fy.split('-')[1]) >2073]\n",
    "fy_dirs.sort()\n",
    "fy_dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_file_details(fy_dir):\n",
    "    \"\"\"\n",
    "    prepare_file_details parses files in fy_dir, and creates structured file detail for every file.\n",
    "    The file detail contains path to file, data year, month and fiscal year\n",
    "\n",
    "    A sorted list of file details is returned. \n",
    "    \"\"\"\n",
    "    base_dir = os.path.join('data', fy_dir)\n",
    "    files = os.listdir(base_dir)\n",
    "    file_details =[] \n",
    "    for file in files:\n",
    "        matches = re.match(r'(\\d{4})-(\\w+).xlsx', file)\n",
    "        if matches:\n",
    "            year, month = matches.group(1), matches.group(2)\n",
    "            month_match = get_close_matches(month, months.keys())\n",
    "            if month_match:\n",
    "                month = months[month_match[0]]\n",
    "            else:\n",
    "                raise Exception(\"unable to parse month from title\", month)\n",
    "            file_details.append({\n",
    "                'path': os.path.join(base_dir, file),\n",
    "                'year': year,\n",
    "                'month': month,\n",
    "                'fy': fy_dir.replace('-', '/')[3:]\n",
    "            })\n",
    "\n",
    "    custom_month_order = [4, 5, 6, 7, 8, 9, 10, 11, 12, 1, 2]\n",
    "    file_details = sorted(file_details, key=lambda x: (x['year'], custom_month_order.index(x['month'])))\n",
    "    return file_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df(path:str):\n",
    "    \"\"\"\n",
    "    get_df returns dataframe by reading file and adjusting header in correct index.\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame({'Unnamed':[1,2,3]})\n",
    "    i = 0\n",
    "    while df.columns.str.contains('^Unnamed').sum() > 0:\n",
    "        df = pd.read_excel(path, sheet_name=5, header=i)\n",
    "        if len(df.columns) == 5:\n",
    "            df = pd.read_excel(path,sheet_name=4,header=i)\n",
    "        i+=1\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_rows(df:pd.DataFrame):\n",
    "    \"\"\"filter_rows filters rows in df and only keeps those with hscode starting with 87. i.e. Transport vehicle related data is filtered\"\"\"\n",
    "    filtered = df[df['hscode'].apply(lambda x: str(x).startswith('87'))]\n",
    "    return filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_monthwise_files(file_details):\n",
    "    \"\"\"\n",
    "    merge_monthwise_files does following jobs:\n",
    "\n",
    "    i. Reads df from file for every month in fiscal year.\n",
    "\n",
    "    ii. Assigns simple column names.\n",
    "\n",
    "    iii. Subtracts cumulated values from current month with cumulated values from previous month to get exact figures.\n",
    "\n",
    "    iv. Filters rows to keep only transport vehicle related rows.\n",
    "\n",
    "    v. Tag month and fiscal year to monthly data.\n",
    "\n",
    "    vi. Merge all months dfs into yearly dataframe and returns it.\n",
    "\n",
    "    \"\"\"\n",
    "    dfs = []\n",
    "    cumulated_cols = ['quantity', 'value', 'revenue']\n",
    "    for i, file_info in enumerate(file_details):\n",
    "        print('Processing file:', file_info['path'])\n",
    "        df = get_df(file_info['path'])\n",
    "        df.columns = ['hscode', 'description', 'unit', *cumulated_cols]\n",
    "\n",
    "        if i > 0:\n",
    "            prev_df = get_df(file_details[i-1]['path'])\n",
    "            prev_df.columns = ['hscode', 'description', 'unit', *cumulated_cols]\n",
    "            df_temp = df.set_index('hscode')\n",
    "            prev_df_temp = prev_df.set_index('hscode')\n",
    "\n",
    "            # Drop duplicate values from the index\n",
    "            df_temp = df_temp[~df_temp.index.duplicated(keep='first')]\n",
    "            prev_df_temp = prev_df_temp[~prev_df_temp.index.duplicated(keep='first')]\n",
    "\n",
    "            df_temp[cumulated_cols] = df_temp[cumulated_cols].subtract(prev_df_temp[cumulated_cols], fill_value=0)\n",
    "            df_temp.reset_index(inplace=True)\n",
    "            \n",
    "            df = df_temp\n",
    "\n",
    "        df = filter_rows(df)\n",
    "\n",
    "        df = df.copy()\n",
    "\n",
    "        # df['year'] = file_info['year']\n",
    "        df['month'] = file_info['month']\n",
    "        df['fy'] = file_info['fy']\n",
    "        dfs.append(df)\n",
    "    \n",
    "    merged_df = pd.concat(dfs, ignore_index=True)\n",
    "    merged_df.dropna(inplace=True)\n",
    "    merged_df = merged_df[['fy', 'month', 'hscode', 'description', 'unit', 'quantity', 'value', 'revenue']]\n",
    "    # merged_df.to_csv(file_details[0]['path'].split('/')[1]+'.csv', index=False)\n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_negatives(df:pd.DataFrame):\n",
    "    \"\"\"\n",
    "    remove_negatives removes -ve values from dataset.\n",
    "\n",
    "    Due to faults in DoC dataset, some rows have -ve values. Those values are subsided gracefully.\n",
    "\n",
    "    If values are negligibly -ve ie. -0.0001 type. Then those values are round up to 0.\n",
    "\n",
    "    Rows with largely negative values are dropped.\n",
    "    \"\"\"\n",
    "    df['quantity'] = df['quantity'].apply(lambda x: x if x > -1 else pd.NA)\n",
    "    df['value'] = df['value'].apply(lambda x: x if x > -1 else pd.NA)\n",
    "    df['revenue'] = df['revenue'].apply(lambda x: x if x > -1 else pd.NA)\n",
    "\n",
    "    df.dropna(inplace=True)\n",
    "\n",
    "    df['value'] = df['value'].apply(lambda x: max(x, 0))\n",
    "    df['quantity'] = df['quantity'].apply(lambda x: max(x, 0))\n",
    "    df['revenue'] = df['revenue'].apply(lambda x: max(x, 0))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each fiscal year:\n",
    "\n",
    "- First prepare file details for the fiscal year directory\n",
    "- Then merge the monthly data to prepare yearly dataframe\n",
    "- Merge all yearly dataframes to create final dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: data/fy-2074-75/2074-shraavnnsmm.xlsx\n",
      "Processing file: data/fy-2074-75/2074-bhaadrsmm.xlsx\n",
      "Processing file: data/fy-2074-75/2074-aashvinsmm.xlsx\n",
      "Processing file: data/fy-2074-75/2074-kaartiksmm.xlsx\n",
      "Processing file: data/fy-2074-75/2074-maargsmm.xlsx\n",
      "Processing file: data/fy-2074-75/2074-pausssmm.xlsx\n",
      "Processing file: data/fy-2074-75/2074-maaghsmm.xlsx\n",
      "Processing file: data/fy-2074-75/2074-phaagunsmm.xlsx\n",
      "Processing file: data/fy-2074-75/2074-caitrsmm.xlsx\n",
      "Processing file: data/fy-2074-75/2075-vaishaakhsmm.xlsx\n",
      "Processing file: data/fy-2074-75/2075-jesstthsmm.xlsx\n",
      "Processing file: data/fy-2075-76/2075-shraavnnsmm.xlsx\n",
      "Processing file: data/fy-2075-76/2075-bhaadrsmm.xlsx\n",
      "Processing file: data/fy-2075-76/2075-aashvinsmm.xlsx\n",
      "Processing file: data/fy-2075-76/2075-kaartiksmm.xlsx\n",
      "Processing file: data/fy-2075-76/2075-maargsmm.xlsx\n",
      "Processing file: data/fy-2075-76/2075-pausssmm.xlsx\n",
      "Processing file: data/fy-2075-76/2075-maaghsmm.xlsx\n",
      "Processing file: data/fy-2075-76/2075-phaagunsmm.xlsx\n",
      "Processing file: data/fy-2075-76/2075-caitrsmm.xlsx\n",
      "Processing file: data/fy-2075-76/2076-vaishaakhsmm.xlsx\n",
      "Processing file: data/fy-2075-76/2076-jesstthsmm.xlsx\n",
      "Processing file: data/fy-2076-77/2076-shraavnnsmm.xlsx\n",
      "Processing file: data/fy-2076-77/2076-bhaadrsmm.xlsx\n",
      "Processing file: data/fy-2076-77/2076-aashvinsmm.xlsx\n",
      "Processing file: data/fy-2076-77/2076-kaartiksmm.xlsx\n",
      "Processing file: data/fy-2076-77/2076-maargsmm.xlsx\n",
      "Processing file: data/fy-2076-77/2076-pausssmm.xlsx\n",
      "Processing file: data/fy-2076-77/2076-maaghsmm.xlsx\n",
      "Processing file: data/fy-2076-77/2076-phaagunsmm.xlsx\n",
      "Processing file: data/fy-2076-77/2076-caitrsmm.xlsx\n",
      "Processing file: data/fy-2076-77/2077-vaishaakhsmm.xlsx\n",
      "Processing file: data/fy-2076-77/2077-jesstthsmm.xlsx\n",
      "Processing file: data/fy-2077-78/2077-shraavnnsmm.xlsx\n",
      "Processing file: data/fy-2077-78/2077-bhaadrsmm.xlsx\n",
      "Processing file: data/fy-2077-78/2077-aashvinsmm.xlsx\n",
      "Processing file: data/fy-2077-78/2077-kaartiksmm.xlsx\n",
      "Processing file: data/fy-2077-78/2077-maargsmm.xlsx\n",
      "Processing file: data/fy-2077-78/2077-pausssmm.xlsx\n",
      "Processing file: data/fy-2077-78/2077-maaghsmm.xlsx\n",
      "Processing file: data/fy-2077-78/2077-phaagunsmm.xlsx\n",
      "Processing file: data/fy-2077-78/2077-caitrsmm.xlsx\n",
      "Processing file: data/fy-2077-78/2078-vaishaakhsmm.xlsx\n",
      "Processing file: data/fy-2077-78/2078-jesstthsmm.xlsx\n",
      "Processing file: data/fy-2078-79/2078-shraavnnsmm.xlsx\n",
      "Processing file: data/fy-2078-79/2078-bhaadrsmm.xlsx\n",
      "Processing file: data/fy-2078-79/2078-asojsmm.xlsx\n",
      "Processing file: data/fy-2078-79/2078-kaartiksmm.xlsx\n",
      "Processing file: data/fy-2078-79/2078-mnsirsmm.xlsx\n",
      "Processing file: data/fy-2078-79/2078-pusssmm.xlsx\n",
      "Processing file: data/fy-2078-79/2078-maaghsmm.xlsx\n",
      "Processing file: data/fy-2078-79/2078-phaagunsmm.xlsx\n",
      "Processing file: data/fy-2078-79/2078-caitrsmm.xlsx\n",
      "Processing file: data/fy-2078-79/2079-vaishaakhsmm.xlsx\n",
      "Processing file: data/fy-2078-79/2079-jetthsmm.xlsx\n",
      "Processing file: data/fy-2079-80/2079-shraavnn.xlsx\n",
      "Processing file: data/fy-2079-80/2079-bhaadrsmm.xlsx\n",
      "Processing file: data/fy-2079-80/2079-aashvinsmm.xlsx\n",
      "Processing file: data/fy-2079-80/2079-kaartiksmm.xlsx\n",
      "Processing file: data/fy-2079-80/2079-mngsirsmm.xlsx\n",
      "Processing file: data/fy-2079-80/2079-pusssmm.xlsx\n",
      "Processing file: data/fy-2079-80/2079-maaghsmm.xlsx\n",
      "Processing file: data/fy-2079-80/2079-phaagunsmm.xlsx\n",
      "Processing file: data/fy-2079-80/2079-caitrsmm.xlsx\n",
      "Processing file: data/fy-2079-80/2080-vaishaakhsmm.xlsx\n",
      "Processing file: data/fy-2079-80/2080-jesstthsmm.xlsx\n",
      "Processing file: data/fy-2080-81/2080-shraavnn.xlsx\n",
      "Processing file: data/fy-2080-81/2080-bhaadrsmm.xlsx\n",
      "Processing file: data/fy-2080-81/2080-asojsmm.xlsx\n",
      "Processing file: data/fy-2080-81/2080-kaartiksmm.xlsx\n",
      "Processing file: data/fy-2080-81/2080-mngsirsmm.xlsx\n",
      "Processing file: data/fy-2080-81/2080-pausssmm.xlsx\n",
      "Processing file: data/fy-2080-81/2080-maaghsmm.xlsx\n"
     ]
    }
   ],
   "source": [
    "yearly_dfs = []\n",
    "\n",
    "for fy_dir in fy_dirs:\n",
    "    file_details = prepare_file_details(fy_dir)\n",
    "    yearly_df = merge_monthwise_files(file_details)    \n",
    "    yearly_dfs.append(yearly_df)\n",
    "\n",
    "final_df = pd.concat(yearly_dfs, ignore_index=True)\n",
    "\n",
    "# some hscodes are interpreted as floats\n",
    "final_df['hscode'] = final_df['hscode'].apply(lambda x: int(x))\n",
    "\n",
    "# output csv\n",
    "final_df.to_csv('extracted.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This applies the `remove_negatives` function to handle negative values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_df = pd.read_csv('extracted.csv')\n",
    "positive_df = remove_negatives(negative_df)\n",
    "positive_df.to_csv('extracted.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
